{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "    ProductKey  BrandKey  SupplierKey ProductCategory_Lvl1  \\\n0    key_52138      3521   1039040101           Category A   \n1        19864      3521   1039040125           Category A   \n2        95144      1713   1049688101           Category A   \n3        23070      3521   1050235101           Category A   \n4        93165      3521   1039040125           Category A   \n..         ...       ...          ...                  ...   \n293      12353      3521   1036290101           Category A   \n294      55442       132   1036290101           Category A   \n295      78206      3521   1039040101           Category A   \n296      55438       132   1036290101           Category A   \n297  key_96971      3521   1036290101           Category A   \n\n    ProductCategory_Lvl2  \n0            category aa  \n1            Category AC  \n2            Category AA  \n3            Category AC  \n4            Category AC  \n..                   ...  \n293          Category AB  \n294          Category AC  \n295          Category AC  \n296          Category AB  \n297          Category AA  \n\n[298 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ProductKey</th>\n      <th>BrandKey</th>\n      <th>SupplierKey</th>\n      <th>ProductCategory_Lvl1</th>\n      <th>ProductCategory_Lvl2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>key_52138</td>\n      <td>3521</td>\n      <td>1039040101</td>\n      <td>Category A</td>\n      <td>category aa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19864</td>\n      <td>3521</td>\n      <td>1039040125</td>\n      <td>Category A</td>\n      <td>Category AC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>95144</td>\n      <td>1713</td>\n      <td>1049688101</td>\n      <td>Category A</td>\n      <td>Category AA</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>23070</td>\n      <td>3521</td>\n      <td>1050235101</td>\n      <td>Category A</td>\n      <td>Category AC</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>93165</td>\n      <td>3521</td>\n      <td>1039040125</td>\n      <td>Category A</td>\n      <td>Category AC</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>293</th>\n      <td>12353</td>\n      <td>3521</td>\n      <td>1036290101</td>\n      <td>Category A</td>\n      <td>Category AB</td>\n    </tr>\n    <tr>\n      <th>294</th>\n      <td>55442</td>\n      <td>132</td>\n      <td>1036290101</td>\n      <td>Category A</td>\n      <td>Category AC</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>78206</td>\n      <td>3521</td>\n      <td>1039040101</td>\n      <td>Category A</td>\n      <td>Category AC</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>55438</td>\n      <td>132</td>\n      <td>1036290101</td>\n      <td>Category A</td>\n      <td>Category AB</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>key_96971</td>\n      <td>3521</td>\n      <td>1036290101</td>\n      <td>Category A</td>\n      <td>Category AA</td>\n    </tr>\n  </tbody>\n</table>\n<p>298 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product = pd.read_csv('Assets/data/Hackathon_DimProduct_SAN_vShared.csv',header=0)\n",
    "df_product"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "ProductKey              object\nBrandKey                 int64\nSupplierKey              int64\nProductCategory_Lvl1    object\nProductCategory_Lvl2    object\ndtype: object"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "def remove_punctuations(ts):\n",
    "    '''Takes a word and removes all punctuations.\n",
    "     :parameter\n",
    "     ts: str\n",
    "        the word to be cleaned\n",
    "    :returns\n",
    "    -----\n",
    "    str\n",
    "        the cleaned version\n",
    "      '''\n",
    "    ts=str(ts)\n",
    "    for punctuation in string.punctuation:\n",
    "        ts = ts.replace(punctuation, '')\n",
    "    return ts\n",
    "\n",
    "def remove_non_numbers(ts):\n",
    "    '''Takes a word and removes all non-digit characters.\n",
    "     :parameter\n",
    "     ts: str\n",
    "        the word to be cleaned\n",
    "    :returns\n",
    "    -----\n",
    "    str\n",
    "        the cleaned version\n",
    "      '''\n",
    "    return int(re.sub('[^0-9.]', '',str(ts)))\n",
    "\n",
    "def name_corrector(ts):\n",
    "    '''Takes a word and removes all whitespaces, transforms it to lowercase,\n",
    "     and connects the words using '_'. Also checks for misspelling.\n",
    "     :parameter\n",
    "     ts: str\n",
    "        the word to be corrected\n",
    "    :returns\n",
    "    -----\n",
    "    str\n",
    "        the corrected version\n",
    "      '''\n",
    "    return re.sub('categrory','category','_'.join(re.sub(' +',' ',ts).lower().split(' ')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['ProductKey', 'BrandKey', 'SupplierKey', 'ProductCategory_Lvl1',\n       'ProductCategory_Lvl2'],\n      dtype='object')"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "df_product_clean = df_product.copy()\n",
    "for col in ['ProductKey', 'BrandKey', 'SupplierKey']:\n",
    "    df_product_clean[col] = df_product[col].apply(remove_punctuations)\n",
    "    df_product_clean[col] = df_product[col].apply(remove_non_numbers)\n",
    "\n",
    "for col in ['ProductCategory_Lvl1','ProductCategory_Lvl2']:\n",
    "    df_product_clean[col]= df_product[col].apply(remove_punctuations)\n",
    "    df_product_clean[col] = df_product[col].apply(name_corrector)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "nlp = spacy.load('it_core_news_sm')\n",
    "import string\n",
    "import re\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "class preprocess_pip():\n",
    "    def __init__(self,df ,column_name):\n",
    "        self.df = df\n",
    "        self.old_text = column_name\n",
    "        self.text = column_name+'_clean'\n",
    "\n",
    "    def apply_preprocessing(self):\n",
    "#         self.df[self.text] =  self.df[self.old_text].astype('string')\n",
    "        self.df[self.text] = self.df[self.old_text].apply(self.na_filter)\n",
    "        self.df.dropna(subset=[self.text],inplace=True)\n",
    "        self.df[self.text] = self.df[self.text].apply(self.remove_punctuations)\n",
    "        self.df[self.text] = self.df[self.text].apply(self.to_lower)\n",
    "        self.df[self.text] = self.df[self.text].apply(self.stop_word_elm)\n",
    "        self.df[self.text] = self.df[self.text].apply(self.deEmojify)\n",
    "        self.df[self.text] = self.df[self.text].apply(self.na_filter)\n",
    "        self.df.dropna(axis=0, how='any',subset=[self.text])\n",
    "#         self.df.drop('index',axis=1,inplace=True)\n",
    "        self.df.reset_index(inplace=True)\n",
    "        self.df.drop('index',axis=1,inplace=True)\n",
    "        self.df[self.text].replace(\"[0-9,â‚¬$-;\\'\\\"]\", '', regex=True,inplace=True)\n",
    "        self.df.dropna(subset=[self.text],inplace=True)\n",
    "        self.df=self.df[self.df[self.text]!='']\n",
    "\n",
    "\n",
    "    def na_filter(self, text):\n",
    "        if len(text)>0:\n",
    "            return text\n",
    "        return\n",
    "\n",
    "    def remove_punctuations(self, text):\n",
    "        text=str(text)\n",
    "        for punctuation in string.punctuation:\n",
    "            text = text.replace(punctuation, '')\n",
    "        return text\n",
    "\n",
    "    def to_lower(self, text):\n",
    "        return text.lower()\n",
    "\n",
    "    def stop_word_elm(self, text):\n",
    "        new_text=[]\n",
    "        for i in text.split():\n",
    "            if i not in italian_stopwords:\n",
    "                new_text.append(i)\n",
    "        return ' '.join(new_text)\n",
    "\n",
    "    def deEmojify(self, text):\n",
    "        regrex_pattern = re.compile(pattern = \"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            \"ðŸ¤®\"\n",
    "            \"ðŸ¤¬\"\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags = re.UNICODE)\n",
    "        return regrex_pattern.sub(r'',text)\n",
    "\n",
    "    def sent_to_words(self, text):\n",
    "        for sentence in text:\n",
    "            yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}